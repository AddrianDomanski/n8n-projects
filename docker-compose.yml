services:
  n8n:
    image: n8nio/n8n
    container_name: n8n
    ports:
      - "5678:5678"
    environment:
      GENERIC_TIMEZONE: "Europe/Warsaw"
      TZ: "Europe/Warsaw"
      N8N_BASIC_AUTH_ACTIVE: "true"
    volumes:
      - n8n_data:/home/node/.n8n
  #  command: ["start", "--tunnel"]
    depends_on:
      - ollama
  
 
  ollama:
    image: ollama/ollama
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    deploy: {}
    runtime: nvidia

volumes:
  n8n_data:
    external: true
  ollama_data:
